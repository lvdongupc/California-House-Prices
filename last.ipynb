{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2835ac03-70fa-4aca-8d60-b36dec7e7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "\n",
    "NUM_SAVE = 50\n",
    "net_list = \"in->256->64\"\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features,256)\n",
    "        self.layer2 = nn.Linear(256,64)\n",
    "        self.out = nn.Linear(64,1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.layer1(X))\n",
    "        X = F.relu(self.layer2(X))\n",
    "        return self.out(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48b7c3e7-bfc2-4182-91e3-a40138197fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data and test_data shape (47439, 41) (31626, 40)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_data = pd.read_csv('train.csv')\n",
    "print(\"train_data and test_data shape\",train_data.shape,test_data.shape)\n",
    "\n",
    "# 去掉冗余数据\n",
    "redundant_cols = ['Address', 'Summary', 'City', 'State']\n",
    "for c in redundant_cols:\n",
    "    del test_data[c], train_data[c]\n",
    "    \n",
    "# 数据预处理\n",
    "large_vel_cols = ['Lot', 'Total interior livable area', 'Tax assessed value', 'Annual tax amount', 'Listed Price', 'Last Sold Price']\n",
    "for c in large_vel_cols:\n",
    "    train_data[c] = np.log(train_data[c]+1)\n",
    "    if c!='Sold Price':\n",
    "        test_data[c] = np.log(test_data[c]+1)\n",
    "\n",
    "# 把train和test去除id后放一起，train也要去掉label\n",
    "all_features = pd.concat((train_data.iloc[:,2:],test_data.iloc[:,1:]))\n",
    "\n",
    "# 时间数据赋日期格式\n",
    "all_features['Listed On'] = pd.to_datetime(all_features['Listed On'], format=\"%Y-%m-%d\")\n",
    "all_features['Last Sold On'] = pd.to_datetime(all_features['Last Sold On'], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c85de24-a4cb-498b-a204-e57139e16368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type                 174\n",
      "Heating              2659\n",
      "Cooling              910\n",
      "Parking              9912\n",
      "Bedrooms             278\n",
      "Region               1259\n",
      "Elementary School    3568\n",
      "Middle School        809\n",
      "High School          922\n",
      "Flooring             1739\n",
      "Heating features     1762\n",
      "Cooling features     595\n",
      "Appliances included  11289\n",
      "Laundry features     3030\n",
      "Parking features     9694\n"
     ]
    }
   ],
   "source": [
    "for in_object in all_features.dtypes[all_features.dtypes=='object'].index:\n",
    "    print(in_object.ljust(20),len(all_features[in_object].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c50f1b9-933a-424f-b21f-2d1726fc61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Use bfill() to backward fill missing values, then fill any remaining missing values with 0\n",
    "all_features = all_features.bfill(axis=0).fillna(0)\n",
    "\n",
    "# Identifying numeric features with dtype 'float64'\n",
    "numeric_features = all_features.dtypes[all_features.dtypes == 'float64'].index\n",
    "\n",
    "# Step 2: Standardize the numeric features\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcb86cd5-cd43-4ea0-a841-4e2a53e7952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(numeric_features)\n",
    "features.extend(['Type','Bedrooms'])   # 加上类别数相对较少的Type, ,'Cooling features'\n",
    "all_features = all_features[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92954c67-e631-493a-87ce-c4ebdb648e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before one hot code (79065, 19)\n",
      "after one hot code (79065, 470)\n"
     ]
    }
   ],
   "source": [
    "print('before one hot code',all_features.shape)\n",
    "all_features = pd.get_dummies(all_features,dummy_na=True)\n",
    "all_features.shape\n",
    "print('after one hot code',all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08414601-f146-44e7-a75c-7f96bcff18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = all_features.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5febf62e-bf33-4cce-9d82-d1adeaf72468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train feature shape: torch.Size([47439, 470])\n",
      "test feature shape: torch.Size([31626, 470])\n",
      "train label shape: torch.Size([47439, 1])\n"
     ]
    }
   ],
   "source": [
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)  # 使用 float32 类型\n",
    "print('train feature shape:', train_features.shape)\n",
    "test_features = torch.tensor(all_features[n_train:].values, dtype=torch.float32)  # 使用 float32 类型\n",
    "print('test feature shape:', test_features.shape)\n",
    "train_labels = torch.tensor(train_data['Sold Price'].values.reshape(-1, 1), dtype=torch.float32)  # 使用 float32 类型\n",
    "print('train label shape:', train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cadf975a-1900-41ac-862f-fa79448f5c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network: MLP(\n",
      "  (layer1): Linear(in_features=470, out_features=256, bias=True)\n",
      "  (layer2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "in_features = train_features.shape[1]\n",
    "net = MLP(in_features).to(device)\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def log_rmse(net, features, labels):\n",
    "    # 确保输入特征和标签也在正确的设备上\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    with torch.no_grad():  # 在计算验证集误差时，不需要计算梯度\n",
    "        # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n",
    "        clipped_preds = torch.clamp(net(features), 1, float('inf'))\n",
    "        rmse = torch.sqrt(criterion(torch.log(clipped_preds),\n",
    "                                torch.log(labels)))\n",
    "    return rmse.item()\n",
    "\n",
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_ls, test_ls = [], []\n",
    "    train_iter = load_array((train_features, train_labels), batch_size)\n",
    "    # 这里使用的是Adam优化算法\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for X, y in train_iter:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        record_loss = log_rmse(net.to('cuda:0'), train_features, train_labels)\n",
    "        train_ls.append(record_loss)\n",
    "        if (epoch%NUM_SAVE==0 and epoch!=0) or (epoch==num_epochs-1):\n",
    "            torch.save(net.state_dict(),'checkpoint_'+str(epoch))\n",
    "            print('save checkpoints on:', epoch, 'rmse loss value is:', record_loss)\n",
    "        del X, y\n",
    "    return train_ls, test_ls\n",
    "\n",
    "num_epochs, lr, weight_decay, batch_size = 500, 0.005, 0.05, 256\n",
    "print(\"network:\",net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d35b673a-f9c7-4f9d-b831-3d576b24c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 51/500 [00:32<04:47,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 50 rmse loss value is: 0.418620765209198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/500 [01:05<04:15,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 100 rmse loss value is: 0.33292049169540405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 151/500 [01:37<03:43,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 150 rmse loss value is: 0.3121003806591034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/500 [02:09<03:02,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 200 rmse loss value is: 0.30113697052001953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 251/500 [02:40<02:39,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 250 rmse loss value is: 0.2916157841682434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/500 [03:12<02:07,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 300 rmse loss value is: 0.2532415986061096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 351/500 [03:45<01:36,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 350 rmse loss value is: 0.23507462441921234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/500 [04:17<01:04,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 400 rmse loss value is: 0.23701271414756775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 451/500 [04:50<00:31,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 450 rmse loss value is: 0.2359466254711151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:21<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save checkpoints on: 499 rmse loss value is: 0.23833008110523224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ls, valid_ls = train(net, train_features,train_labels,None,None, num_epochs, lr, weight_decay, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03f5f253-bc0d-4b40-9b3c-2c2bf0bda652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保模型在GPU上\n",
    "net.to('cuda:0')\n",
    "\n",
    "# 确保测试特征也在同一个设备上，这里是'cuda:0'\n",
    "test_features = test_features.to('cuda:0')\n",
    "\n",
    "# 进行预测\n",
    "preds = net(test_features)\n",
    "\n",
    "# 将预测结果从GPU移动到CPU，并转换为NumPy数组\n",
    "preds = preds.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdec50a1-03f1-4de1-b6c3-0c7bfc0ee8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将其重新格式化以导出到Kaggle\n",
    "test_data['Sold Price'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "submission = pd.concat([test_data['Id'], test_data['Sold Price']], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a02a7f-18e3-4192-b4ea-ad8e25151d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
